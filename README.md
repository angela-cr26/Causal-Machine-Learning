# Implementaci√≥n de causal UberML

## üìã Descripci√≥n del proyecto

Este repositorio contiene una gu√≠a completa y pr√°ctica sobre la implementaci√≥n de t√©cnicas de **Causal Machine Learning** utilizando el paquete **CausalML** desarrollado por Uber. 
El material est√° dise√±ado para servir como la parte aplicativa de un informe sobre Causal ML.

## üéØ Objetivos

- Proporcionar una comprensi√≥n profunda de los conceptos de Causal ML
- Explicar la implementaci√≥n pr√°ctica de meta-learners (S, T, X, R-Learner)
- Demostrar casos de uso reales del mundo empresarial
- Ofrecer c√≥digo ejecutable y bien documentado
- Incluir visualizaciones para facilitar la comprensi√≥n

## üìÅ Estructura del Proyecto

```
.
‚îú‚îÄ‚îÄ README.md                           # Este archivo
‚îú‚îÄ‚îÄ causalml_implementacion.py          # Gu√≠a completa de implementaci√≥n
‚îú‚îÄ‚îÄ causalml_ejemplos_practicos.py      # Casos de uso reales
‚îú‚îÄ‚îÄ causalml_guia_visual.py             # Generaci√≥n de visualizaciones
‚îî‚îÄ‚îÄ visualizaciones/
    ‚îú‚îÄ‚îÄ viz_01_ml_vs_causal.png         # ML tradicional vs Causal ML
    ‚îú‚îÄ‚îÄ viz_02_metalearners.png         # Comparaci√≥n de meta-learners
    ‚îú‚îÄ‚îÄ viz_03_uplift_dist.png          # Distribuci√≥n de uplift
    ‚îú‚îÄ‚îÄ viz_04_uplift_curves.png        # Gain y Qini curves
    ‚îú‚îÄ‚îÄ viz_05_architecture.png         # Arquitectura de CausalML
    ‚îî‚îÄ‚îÄ viz_06_timeline.png             # Timeline de implementaci√≥n
```

## üöÄ Contenido Principal

### 1. **causalml_implementacion.py**

Documento principal que cubre:

#### Conceptos Fundamentales
- ¬øQu√© es Causal Machine Learning?
- CATE (Conditional Average Treatment Effect)
- ITE (Individual Treatment Effect)
- Diferencia con ML tradicional

#### Meta-Learners
- **S-Learner** (Single Learner)
  - Concepto: Un solo modelo con tratamiento como feature
  - Implementaci√≥n paso a paso
  - Ventajas y desventajas
  - C√≥digo con ejemplos

- **T-Learner** (Two Learner)
  - Concepto: Dos modelos separados (control y tratamiento)
  - Implementaci√≥n detallada
  - Cu√°ndo usar este enfoque
  - Ejemplos pr√°cticos

- **X-Learner** (Cross Learner)
  - Concepto: Algoritmo en 3 etapas
  - Imputaci√≥n contrafactual
  - Mejor para datos desbalanceados
  - Implementaci√≥n completa

- **R-Learner** (Robinson Learner)
  - Concepto: Orthogonalization
  - Residualizaci√≥n
  - Propiedades te√≥ricas
  - C√≥digo explicado

#### T√©cnicas Avanzadas
- Propensity Score Estimation
- Propensity Score Matching
- Uplift Trees y Random Forests
- M√∫ltiples tratamientos
- Optimizaci√≥n con costos

#### Evaluaci√≥n
- M√©tricas espec√≠ficas (Qini, AUUC)
- Gain Charts
- Sensitivity Analysis
- Feature Selection para Uplift

### 2. **causalml_ejemplos_practicos.py**

Tres casos de uso completos del mundo real:

#### Caso 1: Optimizaci√≥n de Campa√±a de Email Marketing
```python
Objetivo: Identificar clientes con alta probabilidad de responder
Features: edad, ingresos, engagement, compras previas
Resultado: Mejora de ROI mediante targeting selectivo
```

**Resultados del Ejemplo:**
- ATE Observado: 12.15 puntos porcentuales
- Mejora en targeting: 13.96 pp vs targeting aleatorio
- Ahorro de costos: 80% con targeting selectivo

#### Caso 2: Optimizaci√≥n de Descuentos
```python
Objetivo: Determinar a qui√©n ofrecer descuentos
Segmentos identificados:
  - Sleeping Dogs: No dar descuento (efecto negativo)
  - Lost Causes: No responden
  - Persuadables: TARGET principal
  - Sure Things: Comprar√≠an de todas formas
```

**Insight Clave:** No todos necesitan descuento para comprar

#### Caso 3: Personalizaci√≥n de Canales
```python
Objetivo: Asignar canal √≥ptimo (Email, SMS, Push)
An√°lisis: Efectos heterog√©neos por demograf√≠a
Resultado: Recomendaciones personalizadas por usuario
```

### 3. **causalml_guia_visual.py**

Genera 6 visualizaciones explicativas:

1. **ML vs Causal ML**: Diferencias conceptuales
2. **Meta-Learners**: Comparaci√≥n visual de S/T/X/R-Learners
3. **Uplift Distribution**: Segmentaci√≥n de usuarios
4. **Uplift Curves**: Gain y Qini curves
5. **Arquitectura CausalML**: Estructura del paquete
6. **Timeline**: Fases de implementaci√≥n

## üìä Visualizaciones Generadas

### 1. ML Tradicional vs Causal ML
Explica visualmente la diferencia entre predecir outcomes y estimar efectos causales.

### 2. Comparaci√≥n de Meta-Learners
Diagrama de flujo de cada meta-learner con sus ventajas y desventajas.

### 3. Distribuci√≥n de Uplift
Muestra la distribuci√≥n heterog√©nea de efectos y segmentaci√≥n de usuarios.

### 4. Curvas de Evaluaci√≥n
Gain Curve y Qini Curve para evaluar performance del modelo.

### 5. Arquitectura de CausalML
Diagrama completo de m√≥dulos y m√©todos disponibles.

### 6. Timeline de Implementaci√≥n
Gu√≠a de 12 semanas para implementaci√≥n completa.

## üíª Instalaci√≥n y Uso

### Instalaci√≥n de CausalML

```bash
# Instalaci√≥n b√°sica
pip install causalml

# Con todas las dependencias
pip install causalml[tf,plotting]

# Dependencias necesarias
pip install numpy pandas scikit-learn xgboost matplotlib seaborn
```

### Ejecuci√≥n de Ejemplos

```bash
# Generar visualizaciones
python causalml_guia_visual.py

# Ejecutar casos de uso
python causalml_ejemplos_practicos.py

# Ver implementaci√≥n completa
# (causalml_implementacion.py es un documento educativo)
```

## üìñ Explicaci√≥n de C√≥digo Clave

### Ejemplo: T-Learner Simple

```python
from sklearn.ensemble import GradientBoostingRegressor
import numpy as np

class TLearner:
    def __init__(self):
        self.model_0 = GradientBoostingRegressor()
        self.model_1 = GradientBoostingRegressor()
    
    def fit(self, X, treatment, y):
        # Separar datos por grupo
        idx_control = treatment == 0
        idx_treated = treatment == 1
        
        # Entrenar modelo para control
        self.model_0.fit(X[idx_control], y[idx_control])
        
        # Entrenar modelo para tratamiento
        self.model_1.fit(X[idx_treated], y[idx_treated])
        
        return self
    
    def predict_cate(self, X):
        # Predecir efecto individual
        y0 = self.model_0.predict(X)
        y1 = self.model_1.predict(X)
        
        # CATE = diferencia entre predicciones
        return y1 - y0
```

### Uso con CausalML Real

```python
from causalml.inference.meta import XGBTRegressor
from causalml.dataset import synthetic_data

# Generar datos sint√©ticos
y, X, treatment, tau, b, e = synthetic_data(
    mode=1, n=10000, p=10, sigma=1.0
)

# Entrenar T-Learner con XGBoost
learner = XGBTRegressor(random_state=42)
learner.fit(X, treatment, y)

# Predecir CATE
cate = learner.predict(X)

# Estimar ATE con intervalo de confianza
ate, ate_lb, ate_ub = learner.estimate_ate(X, treatment, y)
print(f'ATE: {ate[0]:.3f} (95% CI: {ate_lb[0]:.3f}, {ate_ub[0]:.3f})')
```

## üéì Conceptos Clave Explicados

### CATE (Conditional Average Treatment Effect)
```
œÑ(x) = E[Y(1) - Y(0) | X = x]
```
El efecto promedio del tratamiento para individuos con caracter√≠sticas X.

### ITE (Individual Treatment Effect)
```
œÑ·µ¢ = Y(1)·µ¢ - Y(0)·µ¢
```
El efecto del tratamiento para un individuo espec√≠fico i.

### Propensity Score
```
e(x) = P(T=1 | X=x)
```
Probabilidad de recibir tratamiento dadas caracter√≠sticas observadas.

### Uplift
```
Uplift = P(Y=1 | T=1, X) - P(Y=1 | T=0, X)
```
Incremento en probabilidad de outcome debido al tratamiento.

## üìà M√©tricas de Evaluaci√≥n

### Qini Score
Mide la ganancia acumulada vs tratamiento aleatorio:
```python
from causalml.metrics import qini_score

qini = qini_score(y_true, uplift_pred, treatment)
```

### AUUC (Area Under Uplift Curve)
√Årea bajo la curva de uplift:
```python
from causalml.metrics import auuc_score

auuc = auuc_score(y_true, uplift_pred, treatment)
```

### Gain Chart
Visualiza ganancia incremental:
```python
from causalml.metrics import plot_gain

fig, ax = plot_gain(y_true, uplift_pred, treatment)
```

## üîß Workflow Completo

### 1. Preparaci√≥n de Datos
```python
# Cargar y limpiar datos
df = pd.read_csv('data.csv')

# Definir features, treatment, outcome
X = df[feature_columns]
treatment = df['treatment']
y = df['outcome']

# Split train/test
X_train, X_test, t_train, t_test, y_train, y_test = \
    train_test_split(X, treatment, y, test_size=0.3)
```

### 2. Estimar Propensity Score
```python
from causalml.propensity import ElasticNetPropensityModel

pm = ElasticNetPropensityModel(n_fold=5, random_state=42)
propensity = pm.fit_predict(X_train, t_train)
```

### 3. Entrenar Modelos
```python
from causalml.inference.meta import BaseXRegressor
from xgboost import XGBRegressor

# X-Learner con XGBoost
x_learner = BaseXRegressor(learner=XGBRegressor())
x_learner.fit(X_train, t_train, y_train, p=propensity)
```

### 4. Predecir CATE
```python
# Predecir efectos individuales
cate_pred = x_learner.predict(X_test)
```

### 5. Evaluar
```python
from causalml.metrics import qini_score, plot_gain

# Calcular m√©tricas
qini = qini_score(y_test, cate_pred, t_test)

# Visualizar
fig, ax = plot_gain(y_test, cate_pred, t_test)
```

### 6. Definir Estrategia
```python
# Identificar usuarios de alto uplift
threshold = np.percentile(cate_pred, 80)
high_uplift = cate_pred >= threshold

# Aplicar targeting selectivo
target_users = df_test[high_uplift]
```

## üéØ Casos de Uso Empresariales

### Marketing
- **Optimizaci√≥n de campa√±as**: Target usuarios que responder√°n
- **Personalizaci√≥n**: Mensaje/canal √≥ptimo por usuario
- **Presupuesto**: Maximizar ROI con targeting selectivo

### E-commerce
- **Descuentos**: A qui√©n dar descuento para maximizar profit
- **Promociones**: Identificar "persuadables"
- **Retenci√≥n**: Intervenciones efectivas por segmento

### Producto
- **Features**: Qu√© features tienen mayor impacto
- **A/B testing**: Identificar heterogeneidad en efectos
- **Personalizaci√≥n**: Experiencia √≥ptima por usuario
